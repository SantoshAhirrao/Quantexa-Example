package com.quantexa.example.etl.projects.fiu.customer

import java.time.LocalDate

import cats.effect.IO
import com.quantexa.scriptrunner.{NoConfigSparkScript, QuantexaSparkScript}
import com.quantexa.scriptrunner.util.metrics.ETLMetricsRepository
import com.quantexa.acl.AclModel.{PrivilegeSetId, SubjectPrivilegeSetMapping}
import com.quantexa.acl.AclAPI.PrivilegeSetUpdatedResponse
import com.quantexa.graph.script.utils.TaskUtils.allPrivilegesForDefinition
import com.quantexa.security.api.SecurityModel.{RoleId, UserId}
import com.quantexa.explorer.tasks.rest.{CreateTaskListBody, CreateTaskListDefinitionBody, UpdateTaskListDefinitionPrivilegeSetBody}
import com.quantexa.engSpark.model.EngModel.NetworkOutput
import com.quantexa.engSpark.model.ResolverModel
import com.quantexa.engSpark.utils.ExplorerFormatter.{formatNetworks, resolutionTemplates}
import com.quantexa.example.etl.projects.fiu.rest.TaskRestClient
import com.quantexa.example.etl.projects.fiu.rest.TaskRestClient._
import com.quantexa.example.etl.projects.fiu.rest.InvestigationRestClient._
import com.quantexa.example.etl.projects.fiu.rest.RestClientUtils.{roleKeyEncoder, userKeyEncoder}
import com.quantexa.explorer.tasks.api.Model.TaskListId
import com.quantexa.explorer.tasks.api.TaskAPI.{CreateTaskListDefinitionResponse, CreateTaskTypeResponse, TaskDataField, TaskDataSchema}
import com.quantexa.graph.script.utils.RestScalaClient.memoize
import com.quantexa.investigation.api.GraphCustodianProtocol.InitialiseGraphResponse
import org.apache.log4j.Logger
import org.apache.spark.sql.{Dataset, SparkSession}
import io.circe.Json
import io.circe.syntax._
import io.circe.generic.auto._
import org.apache.spark.sql

/***
  * QuantexaSparkScript used to create tasks for networks generated by Batch Resolver
  *
  * Loading tasks into a task list in the UI requires the following steps:
  * Create a new task type which decides which score set to apply to all the tasks which use it
  * Create a new task list definition as a wrapper for generating task lists
  * Give the task list definition a set of privileges, this script gives the task list definition all available privileges
  * Create a task list based on the task list definition
  * Load all the networks which tasks are being created from as investigations into the UI
  * Finally load the generated investigations into the task list
  *
  * These steps can all be checked inside the UI either in the admin tab (requires login in as an admin) or the task list tab
  * The way to manage tasks inside the UI is explained at https://quantexa.atlassian.net/wiki/spaces/Docs/pages/253853788/Task-based+Privileges
  */

object CreateTasks extends NoConfigSparkScript {
  val name = "FIU Task Loading"

  //The task list name needs to be changed inbetween runs to avoid name conflicts
  val taskListName = s"IDETest_${LocalDate.now().toString}"
  val taskListDescriptionName = s"TaskListDescriptionTypeName_$taskListName"
  val taskListDescriptionPriviligesName = s"TaskListDescriptionPrivilegesName_$taskListName"
  val taskTypeName = s"TaskTypeName_$taskListName"
  val taskTypeDesc = Some(s"Description of $taskTypeName")
  val scoreSet = "fiu-smoke"

  val resolutionTemplate = "default"

  def fileDependencies: Map[String, String] = Map.empty

  def scriptDependencies = Set.empty[QuantexaSparkScript]

  def createTaskListDefinitionRequest(taskTypeResponse: CreateTaskTypeResponse): Json = {
    CreateTaskListDefinitionBody(
      taskListDescriptionName,
      Some("OfflineTrial"),
      Some(taskTypeResponse.id.value),
      "fiu-smoke",
      Some(new TaskDataSchema(Map[String, TaskDataField]())),
      Some(new TaskDataSchema(Map[String, TaskDataField]())),
      None,
      None
    ).asJson
  }

  def createUpdateTaskListDefinitionPrivilegesRequest(taskListDefinitionResponse: CreateTaskListDefinitionResponse): Json = {
    UpdateTaskListDefinitionPrivilegeSetBody(
      name = taskListDescriptionPriviligesName,
      privileges = allPrivilegesForDefinition(taskListDefinitionResponse.id, new TaskDataSchema(Map[String, TaskDataField]()), new TaskDataSchema(Map[String, TaskDataField]()))
    ).asJson
  }

  def createTaskListRequest(username: String, taskListDefinitionResponse: CreateTaskListDefinitionResponse, taskListDefinitionPrivilegeResponse: PrivilegeSetUpdatedResponse): Json = {
    CreateTaskListBody(
      name = taskListName,
      taskListDefinitionId = taskListDefinitionResponse.id.value,
      description = None,
      privileges = Some(new SubjectPrivilegeSetMapping(Map(new RoleId("User") -> Set(new PrivilegeSetId(taskListDefinitionPrivilegeResponse.updated.id.value))), Map(new UserId(username) -> Set(new PrivilegeSetId(taskListDefinitionPrivilegeResponse.updated.id.value)))))
    ).asJson
  }

  def createTaskRequest(investigation: InvestigationRequest, taskListId: String, taskId: InitialiseGraphResponse): Json = {
    TaskRestClient.CreateTaskRequest(investigation.name.get,
      taskListId,
      new TaskListId(taskId.id.value),
      investigation.resolverRequest.documents.head.docIds.head,
      "quantexa-demo",
      Some(())).asJson
  }

  def run(spark: SparkSession,
          logger: Logger,
          args: Seq[String],
          etlMetricsRepository: ETLMetricsRepository): Unit = {

    import spark.implicits._
    implicit val taskCreationRequestEncoder: sql.Encoder[IO[String]] = org.apache.spark.sql.Encoders.kryo[IO[String]]
    implicit val taskCreationResponseEncoder: sql.Encoder[Either[scala.Throwable, String]] = org.apache.spark.sql.Encoders.kryo[Either[scala.Throwable, String]]

    val (resolveConfigPath, engRootDirectory, loginAPIURL, explorerAPIURL, username, password) = args match {
      case resolveConfigPath :: engRootDirectory :: loginAPIURL :: explorerAPIURL :: username :: password :: Nil =>
        (resolveConfigPath, engRootDirectory, loginAPIURL, explorerAPIURL, username, password)
      case _ => throw new IllegalArgumentException(
        "Please supply <resolve-config.json> <engRootDirectory> <loginAPIURL> <explorerAPIURL> <adminBatchAPIUsername> <adminBatchAPIPassword>"
      )
    }

    //TODO: This is a bug workaround as in IP-621. The entities should be taken from the resolver config again when it is fixed
    //    val resolverConfig = ResolverConfigReader.read(new FileInputStream(resolveConfigPath))
    //      .getOrElse(throw new IllegalArgumentException("Invalid Resolver Config"))

    // Gather a list of entities from the supplied configuration via the getEntityConfiguration utility function
    //    val definedEntities = getEntityConfiguration(resolverConfig,resolutionTemplate).keys.toSeq.distinct
    val definedEntities = Seq("address", "business", "individual", "telephone", "account")

    //Load the ENG Networks
    val networksDS = spark.read
      .parquet(s"$engRootDirectory/NetworkBuild/network_output.parquet")
      .distinct
      .as[NetworkOutput]

    //Project specific logic here to subset the eng networks to those you wish to create tasks for
    val networksSubSetDS = networksDS.limit(20)

    // Use the formatNetworks utility function to transform networks to resolver requests for loading investigations
    val resolverRequestNetworkIdDS: Dataset[(ResolverModel.Request, String)] = formatNetworks(
      networksSubSetDS,
      resolutionTemplates(definedEntities, resolutionTemplate)
    )

    //Creates a dataset with investigation requests for the desired networks
    val investigationRequestDS = resolverRequestNetworkIdDS.map {
      case (resolverRequest, networkID) =>
        InvestigationRequest(
          resolverRequest,
          Some(true),
          Some("FIU_Investigation_" + networkID),
          None
        )
    }

    val rowCount = investigationRequestDS.count
    logger.info(s"Posting $rowCount rows to explorer database")

    val taskTypeRequest = CreateTaskTypeRequest(taskTypeName, None, scoreSet).asJson

    //Generate a task list
    val taskListIdAttempt = for {
      //Create a new task type
      taskTypeResponse <- loadTaskType(taskTypeRequest, loginAPIURL, explorerAPIURL, username, password)
      _ = logger.info(s"Task type successfully loaded with response ${taskTypeResponse.id.value}")

      //Load a task list definition
      taskListDefinitionRequest = createTaskListDefinitionRequest(taskTypeResponse)
      taskListDefinitionResponse <- loadTaskListDefinition(taskListDefinitionRequest, loginAPIURL, explorerAPIURL, username, password)
      _ = logger.info(s"Task list definition successfully loaded with response ${taskListDefinitionResponse.id.value}")

      //Give the generated task list definition all the privileges
      taskListDefinitionPrivilegeRequest = createUpdateTaskListDefinitionPrivilegesRequest(taskListDefinitionResponse)
      taskListDefinitionPrivilegeResponse <- loadTaskListDefinitionPrivilege(taskListDefinitionPrivilegeRequest, taskListDefinitionResponse.id.value, loginAPIURL, explorerAPIURL, username, password)
      _ = logger.info(s"Task list definition privileges successfully loaded with response ${taskListDefinitionPrivilegeResponse.updated.id.value}")

      //Load a new task list
      taskListCreationRequest = createTaskListRequest(username, taskListDefinitionResponse, taskListDefinitionPrivilegeResponse)
      taskListResponse <- loadTaskList(taskListCreationRequest, loginAPIURL, explorerAPIURL, username, password)
      _ = logger.info(s"Task list successfully loaded with response ${taskListResponse.id.value}")
    } yield taskListResponse.id.value

    val taskListId = taskListIdAttempt.unsafeRunSync()

    //Load tasks to the task list
    val loadTasksResponseAttempts = investigationRequestDS.map(investigation => {
      for {
        //Load a network as an investigation
        taskId <- loadInvestigation(investigation.asJson, loginAPIURL, explorerAPIURL, username, password)

        //Load the investigation as a task
        taskRequest = createTaskRequest(investigation, taskListId, taskId)
        taskLoadResponse <- loadTask(taskRequest, loginAPIURL, explorerAPIURL, username, password)
      } yield taskLoadResponse.value
    })

    val loadTasksResponses = loadTasksResponseAttempts.map(_.attempt.unsafeRunSync())

    //Error handling
    val failures = loadTasksResponses.rdd.collect { case message if message.isLeft => message.left.get.getMessage }
    val numberOfFailures = failures.count

    if (numberOfFailures == 0) {
      logger.info(s"All requests succeeded!")
    } else {
      logger.info(s"${rowCount - numberOfFailures} requests succeeded!")
      logger.info(s"$numberOfFailures requests didn't succeed!")
    }
  }
}
